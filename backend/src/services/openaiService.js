// services/openaiService.js

const OpenAI = require("openai");

class OpenAIService {
  constructor() {
    this.client = null;
    this.model = process.env.OPENAI_MODEL || "gpt-3.5-turbo";
    this.maxTokens = parseInt(process.env.OPENAI_MAX_TOKENS) || 1000;
    this.pricing = {
      "gpt-3.5-turbo": { input: 0.0005, output: 0.0015 },
      "gpt-4": { input: 0.03, output: 0.06 },
      "gpt-4-turbo": { input: 0.01, output: 0.03 },
      "gpt-4o": { input: 0.005, output: 0.015 },
      "gpt-4o-mini": { input: 0.00015, output: 0.0006 },
    };
  }

  /**
   * Initialize OpenAI client
   */
  initialize() {
    if (!this.client && process.env.OPENAI_API_KEY) {
      this.client = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY,
      });
    }
    return this.client;
  }

  /**
   * Check if service is configured
   */
  isConfigured() {
    return !!process.env.OPENAI_API_KEY;
  }

  /**
   * Get system prompt
   */
  getSystemPrompt() {
    return `B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh c·ªßa h·ªá th·ªëng qu·∫£n l√Ω H·ªôi D√≤ng Th√°nh Phaol√¥ Thi·ªán B·∫£n.

Nhi·ªám v·ª• c·ªßa b·∫°n:
1. Tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ n·ªØ tu, h√†nh tr√¨nh ∆°n g·ªçi, c·ªông ƒëo√†n d·ª±a tr√™n d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p
2. Gi·∫£i th√≠ch th√¥ng tin m·ªôt c√°ch r√µ r√†ng, d·ªÖ hi·ªÉu
3. S·ª≠ d·ª•ng ng√¥n ng·ªØ t√¥n tr·ªçng, l·ªãch s·ª±
4. N·∫øu kh√¥ng c√≥ ƒë·ªß th√¥ng tin, h√£y th√†nh th·∫≠t n√≥i r·∫±ng b·∫°n kh√¥ng bi·∫øt
5. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát

C√°c giai ƒëo·∫°n ∆°n g·ªçi trong h·ªá th·ªëng:
- T√¨m hi·ªÉu (Inquiry): Giai ƒëo·∫°n ƒë·∫ßu ti√™n khi t√¨m hi·ªÉu v·ªÅ ƒë·ªùi tu
- Ti·ªÅn t·∫≠p vi·ªán (Pre-postulancy): Chu·∫©n b·ªã tr∆∞·ªõc khi v√†o t·∫≠p vi·ªán
- T·∫≠p vi·ªán (Postulancy): Giai ƒëo·∫°n t·∫≠p vi·ªán
- Nh√† t·∫≠p (Novitiate): Giai ƒëo·∫°n nh√† t·∫≠p, h·ªçc h·ªèi s√¢u h∆°n v·ªÅ ƒë·ªùi tu
- Kh·∫•n t·∫°m (Temporary Vows): ƒê√£ kh·∫•n l·∫ßn ƒë·∫ßu, cam k·∫øt t·∫°m th·ªùi
- Kh·∫•n tr·ªçn (Perpetual Vows): Kh·∫•n vƒ©nh vi·ªÖn, cam k·∫øt tr·ªçn ƒë·ªùi

L∆∞u √Ω:
- Lu√¥n d·ª±a tr√™n d·ªØ li·ªáu th·ª±c t·∫ø ƒë∆∞·ª£c cung c·∫•p
- Kh√¥ng b·ªãa ƒë·∫∑t th√¥ng tin
- Tr√¨nh b√†y c√≥ c·∫•u tr√∫c, d·ªÖ ƒë·ªçc
- S·ª≠ d·ª•ng emoji ph√π h·ª£p ƒë·ªÉ l√†m cho c√¢u tr·∫£ l·ªùi sinh ƒë·ªông h∆°n`;
  }

  /**
   * Chat with OpenAI
   */
  async chat(userMessage, context = null, conversationHistory = []) {
    try {
      // Initialize client if not already
      if (!this.initialize()) {
        return {
          success: false,
          message:
            "D·ªãch v·ª• AI ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng li√™n h·ªá qu·∫£n tr·ªã vi√™n.",
          error: "OpenAI API key not configured",
        };
      }

      // Build messages array
      const messages = [
        {
          role: "system",
          content: this.getSystemPrompt(),
        },
      ];

      // Add conversation history (last 10 messages for context)
      if (conversationHistory.length > 0) {
        const recentHistory = conversationHistory.slice(-10);
        recentHistory.forEach((msg) => {
          messages.push({
            role: msg.role === "user" ? "user" : "assistant",
            content: msg.content,
          });
        });
      }

      // Add context from database
      if (context && context.text) {
        messages.push({
          role: "system",
          content: `üìä D·ªØ li·ªáu li√™n quan t·ª´ h·ªá th·ªëng:\n\n${context.text}`,
        });
      }

      // Add user message
      messages.push({
        role: "user",
        content: userMessage,
      });

      // Call OpenAI API
      const completion = await this.client.chat.completions.create({
        model: this.model,
        messages: messages,
        max_tokens: this.maxTokens,
        temperature: 0.7,
        top_p: 1,
        frequency_penalty: 0,
        presence_penalty: 0,
      });

      const response = completion.choices[0].message.content;
      const usage = completion.usage;

      // Calculate cost
      const cost = this.calculateCost(usage);

      return {
        success: true,
        message: response,
        tokens: usage.total_tokens,
        promptTokens: usage.prompt_tokens,
        completionTokens: usage.completion_tokens,
        cost: cost,
        model: this.model,
        context: context,
      };
    } catch (error) {
      console.error("OpenAI API Error:", error.message);

      // Handle quota exceeded - return context-based response
      if (error.status === 429 || error.code === "insufficient_quota") {
        // Fallback: return context data directly
        if (context && context.text) {
          return {
            success: true,
            message: `‚ö†Ô∏è *Ch·∫ø ƒë·ªô offline - D·ªØ li·ªáu t·ª´ h·ªá th·ªëng:*\n\n${context.text}\n\n_L∆∞u √Ω: AI ƒëang t·∫°m ng∆∞ng, ƒë√¢y l√† d·ªØ li·ªáu tr·ª±c ti·∫øp t·ª´ database._`,
            tokens: 0,
            cost: 0,
            model: "offline-fallback",
          };
        }
        return {
          success: false,
          message:
            "‚ö†Ô∏è H·ªá th·ªëng AI ƒë√£ h·∫øt quota. Vui l√≤ng li√™n h·ªá qu·∫£n tr·ªã vi√™n ƒë·ªÉ n·∫°p th√™m credit OpenAI.",
          error: error.message,
        };
      }

      if (error.code === "rate_limit_exceeded") {
        return {
          success: false,
          message:
            "H·ªá th·ªëng ƒëang b·∫≠n, vui l√≤ng th·ª≠ l·∫°i sau v√†i gi√¢y.",
          error: error.message,
        };
      }

      return {
        success: false,
        message:
          "Xin l·ªói, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n l√∫c n√†y. Vui l√≤ng th·ª≠ l·∫°i sau.",
        error: error.message,
      };
    }
  }

  /**
   * Calculate cost based on token usage
   */
  calculateCost(usage) {
    const pricing = this.pricing[this.model];

    if (!pricing) {
      return 0;
    }

    const inputCost = (usage.prompt_tokens / 1000) * pricing.input;
    const outputCost = (usage.completion_tokens / 1000) * pricing.output;

    return parseFloat((inputCost + outputCost).toFixed(6));
  }

  /**
   * Get model info
   */
  getModelInfo() {
    return {
      model: this.model,
      maxTokens: this.maxTokens,
      pricing: this.pricing[this.model] || null,
      isConfigured: this.isConfigured(),
    };
  }
}

module.exports = new OpenAIService();
